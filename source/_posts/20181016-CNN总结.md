---
title: CNN总结
date: 2018-10-16 09:16:43
tags: [CNN, 深度学习]
---
#### 0.基本概念
- 卷积的预定义参数可以被视为权重矩阵的先验，卷积核的大小，filter的数量,这些都是预定义的网络参数。
- 全连接层也是一种卷积层，它的参数基本核卷积层的参数一样，卷积核大小核原始数据大小一样。全连接层起到了将学到的“分布式特征表示”映射到样本标记空间的作用。(全连接层参数占整个网络参数的80%左右，全连接层的卷积核横截面积做得核输入feature map一样大)
- Sample: 样本，数据集中的一个元素，一条数据。
	例1: 在卷积神经网络中，一张图像是一个样本。
	例2: 在语音识别模型中，一段音频是一个样本。
- Batch: 批，含有 N 个样本的集合。每一个 batch 的样本都是独立并行处理的。在训练时，一个 batch 的结果只会用来更新一次模型。  - 一个 batch 的样本通常比单个输入更接近于总体输入数据的分布，batch 越大就越近似。然而，每个 batch 将花费更长的时间来处理，并且仍然只更新模型一次。在推理（评估/预测）时，建议条件允许的情况下选择一个尽可能大的 batch，（因为较大的 batch 通常评估/预测的速度会更快）。
- Epoch: 轮次，通常被定义为 「在整个数据集上的一轮迭代」，用于训练的不同的阶段，这有利于记录和定期评估。
- img2col 优化卷积运算，转换成矩阵相乘。

####  1.为什么CNN适用于图像？
- 图片的模式（特征）不需要看整个图片，看小区域就行。（有没有鸟嘴出现？）convolution
- 相同的模式（特征）出现在不用的区域。共用参数。convolution
- 像素的二次抽样不会改变图像的形状，图片减小，参数减小。max pooling


####  2.CNN架构
图片 ->  convolution -> max pooling -> convolution -> max pooling ....-> flatten -> fully connected  feedforward netword


####  3.CNN实践keras

**convolution:** model2.add(Convolution2D(25,3,3, input_shape=(1,28,28)))备注：１黑白25个特征3\*3卷积
**max pooling:** model2.add(MaxPooling2D((2,2)))
**flatten:** model2.add(Flatten)
**fully connected:** model2.add(Dense(output_dim=100)) model2.add(Activation('relu'))
model2.add(Dense(output_dim=10)) model2.add(Activation('softmax'))


